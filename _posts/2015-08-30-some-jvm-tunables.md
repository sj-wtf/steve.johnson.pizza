---
layout: post
title: Some JVM Tunables
description:
headline: Because the JVM is fickle
modified: 2016-08-30
category: tech
tags: [update, java, jvm]
image:
---
Tuning the JVM is an important part of being an administrator of Java applications.  I am by no means an expert, but there are some pretty basic things you can do to make sure your Java application runs reliably and in a performant manner.  These include making sure that your application has enough memory of various types, specifying a garbage collection scheme (if the default doesn’t work for you), making sure it comes back when it runs out of memory, and a couple other tips and tricks. I personally use OpenJDK 1.7_79, but most of these flags should be available to other JVM distributions as well.


The first and easiest thing to do is add more heap memory to applications that run out.  Heap memory is where objects and their instance variables live, so if you’re modeling a very large dataset with Java objects, then you’re going to need a large quantity of heap memory.  By default, when a Java application runs out of heap memory, it shuts down completely and doesn’t process any more data, so it’s in your best interests to make sure your application has enough memory to breathe.  The default heap size for most JVM implementations is the smaller of 1/4th of main memory, or 1GB.  As we move towards processing larger and larger datasets, that’s rarely sufficient.  You’ll want to increase the size of the heap memory available to your app.  It’s pretty easy to do this, just add `-Xmx<new max size of heap>`.  You can specify several different units.  `-Xmx1024m` is the same as `-Xmx1g`.

It can sometimes take time to allocate memory, and the maximum heap size isn’t allocated at startup by default.  For better performance, you can specify a minimum heap size in much the same way as the maximum heap size with the flag `-Xms<new minimum heap size>`.  Memory allocation from the OS through malloc() takes some time.  If you front-load allocating memory from the OS by specifying a larger minimum heap size, the JVM will have to call malloc() fewer times when your application is doing heavy listing and allocating more heap memory for objects, which is when performance really matters.

I’ll probably do another post on just garbage collection somewhere down the road, but I’ll assume the readers of this post know how heap memory is segmented into an old generation and a new generation.  The tunables available to us operate on either one or both by allowing us to specify a specific type of GC on a specific generation to increase performance. We can specify that we want to use parallel GC (meaning that the garbage collection is multithreaded) with the flags `-XX:+UseParNewGC`, `-XX:+UseParallelOldGC`, and `-XX:+UseParallelGC`. The first two operate on specific generations, while the last flag operates on all memory. You can specify the number of threads you want to use with the flag `-XX:ParallelGCThreads=`. `-XX:+UseConcMarkSweepGC` uses a type of GC called Concurrent mark and Sweep that pauses the JVM only during specific steps, however it only operates on the old generation. IMO, it’s best to use parallel garbage collection on the new generation, and concurrent mark and sweep for the old generation. That minimizes the duration of pauses, and makes sure that your code keeps running fairly smoothly!

It’s inevitable that your application runs out of memory for one reason or another. It happens silently if you don’t have alerting set up; your app just stops doing things. Most folks I know hate to get up in the middle of the night to restart a service, when you could avoid it and make your application more robust with a simple flag, while still providing you with all the information you need about the cause of the issue. You can kill and restart your application using `-XX:OnOutOfMemoryError=`, that way you minimize downtime when an OutOfMemory error occurs. If you want information about what caused the JVM to run out of memory, you can generate a heap dump with `-XX:+HeapDumpOnOutOfMemoryError`. Make sure you ship it off the box so you don’t run out of disk space when you’re not paying attention.  Anyone operations engineer who doesn’t want to be up in the middle of the night to restart a service should do this to all their JVM apps.  Use OnOutOfMemoryError to kill the pid (JVM graciously gives you a PID variable called %p), then have a supervisor service start it back up, and wake you up if it happens more than X (3 is pretty good, IMO) times in Y (15 min is pretty good, IMO) time.

There are plenty of other tunables available to the administrators of JVM applications, and you can learn more about them by checking the documentation for your JVM distribution.  I’ll probably do an article focusing on Garbage Collection next, so watch for that.
