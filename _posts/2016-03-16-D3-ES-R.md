---
layout: post
title: Elasticsearch, R, and D3.js for log analysis
description:
headline: Logfile Analysis
modified: 2016-03-16
category: tech
tags: [update, d3, d3.js, r, elasticsearch]
image:
---
Many of you are probably familiar with the challenges of logging.  Before you go into production and you or your support group starts using the logs, it’s hard to tell what’s going to be useful and what’s not.  Many developers choose to log everything and the kitchen sink just to be safe, but that just generates useless noise that you’ll have to wade through later.  In some environments, there are requirements on how long to retain logs, which in addition to the log volume increase as you scale out, will eventually cause you a big data problem.  Back in the days when I supported smaller systems, I could tail a services' log and determine what it was doing by the shape made by groupings of log lines, if I disabled line wrapping.  There’s no way that you can do that in a larger environment, and while Kibana is an excellent tool, it can’t be as flexible as a whole language dedicated to data analysis (and it shouldn’t be; it’s a wonderful general-purpose tool).  R allows you to build data models that match your actual data, and D3.js provides a versatile front-end for the analyzed data.

In the environment I’m working in, we use Elasticsearch for log storage.  We haven’t mastered it yet, but we certainly take advantage of the flexibility of the data format.  We have nearly 80 different fields, most of which are strings, which can cause runaway memory usage on our Elasticsearch nodes.  Elasticsearch has an HTTP API, so we could use a library, or we could just do it ourselves.  You're going to be forming your queries in the same way both ways, so why learn a new interface.

I mentioned it earlier in this post, but it’s worth mentioning again that there’s no reason to use these tools for basic analysis, such as number of documents fitting a specific criteria.  Elasticsearch handles these simple aggregations internally, which we will take advantage of.  In some other use cases, you may want to handle these in the code you wrote rather than making Elasticsearch do it.  The use case we’ve got here is somewhat common: we have a group of microservices that spend a lot of time talking to each other for each externally initiated request.  We want to be able to trace the requests in a timeline or tree, so we can understand exactly what each client request spawns on the microservices side, and determine if we can waste less time on interprocess communication.  We’re assuming that the clocks on the individual microservice nodes are reliable (they are more-or-less accurate, I’ve checked).  There’s a shared substring in a specific field that we can use to track requests spanning outward in most cases, but because the folks who developed the server-side code in some cases didn’t develop an accompanying client library, that’s not always the case, so we’ll have to add fuzzy time-matching too.  In the code, I created a distinct vector for each initiating request, so I can map out what start request triggers what interprocess requests.

Once we’ve got everything grouped into vectors how we want them in R, we can dump them out to json files for D3.js to read.  I chose to write an individual file for each distinct request that initiated all the server-side requests.  Each row is a request, with a start time, end time, initiating path, and destination path (if applicable, some requests don’t spawn other requests).  A Gantt chart makes the most sense to me to represent this data, since I want to know how long each request takes to be completed on each individual server, and there can be multiple concurrent outstanding requests at any given time.  D3 has a really nice Gantt chart that’s really simple to use.  Here’s an example showing how to use it:

```
var tasks = [
  {
    "start_time":new Date(1458097631),
    "end_time":new Date(1458097929),
    "initiating_uri":"/consumer_request/a_resource",
    "destination_uri":"/a/b/c"
  },
  {
    "start_time":new Date(1458097929),
    "end_time":new Date(1458097975),
    "initiating_uri":"/a/b/c",
    "destination_uri":"/d/e/f"
  },
  {
    "start_time":new Date(1458097975),
    "end_time":new Date(1458098000),
    "initiating_uri":"/d/e/f",
    "destination_uri":"/g/h/i"
  },
  {
    "start_time":new Date(1458097975),
    "end_time":new Date(1458098200),
    "initiating_uri":"/d/e/f",
    "destination_uri":"/j/k/l"
  }
];

task_names = []

for(i=0, i<tasks.length, i++ ){
  cur_task = tasks[i]
  task_names.push(cur_task['destination_uri'])
};

var max_date = tasks[tasks.length - 1].end_time;
var min_date = tasks[0].start_time;
var format = "%M";
var timeDomainString = "1hour";
var gantt = d3.gantt().taskTypes(task_names).tickFormat(format).height(450).width(800);
gantt.timeDomainMode("fixed");
changeTimeDomain(timeDomainString);
gantt(tasks);
```

I’m sure you get the idea; it’s simple to use D3.js to visualize your data.  This is just one chart type that D3 supports, it’s an incredibly useful tool that can be used to visualize data with every chart type I can think of.  I don’t think I’d use R again for this kind of use case, since I’m not doing anything with R that I can’t do with Python, and I’m much more familiar with Python.  For most common use cases, there's a matplotlib graph for it, so there's usually no case for d3.js unless you're looking for a special type of chart.
